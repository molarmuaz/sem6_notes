## Goals
Essentially, we want to speed up our program as much as we can. For this we want to parallelize instructions, however we can only parallelize **independent** instructions.

### DOALL Loops
As the name suggests in a DOALL loop we can execute all the iterations simultaneously, making it completely independent.
```cpp
//Example: A loop that doubles each element. 
for(int i = 0; i<10;i++)
{
	a[i] = a[i]*2;
}
//Since only its own memory is involved, it is only depending on itself, i.e. independent.

//Whereas something like
for(int i = 1; i<10;i++)
{
	a[i] = a[i-1]*2;
}
//is dependant on the previous memory. This means that we need to have a[i-1] computed before we can compute a[i] making it not possible to parallelize.
```

#### Definition
A **dependence** is a relationship between 2 computations that places constraints on their execution order. **Dependence analysis** identifies these *constraints*

**Constraints** are used to determine whether a particular transformation can be applied without changing the computation’s semantics

#### Types
**Control Dependence:** There is a control dependence between S1 and S2, when S1 determines whether S2 will be executed or not.
```cpp
S1 -> if(T != 0)
S2 ->     A = A/T;

//Executing S2 before S1 could cause a divide by zero exception
```

**Data Dependence:** There is a data dependence between S1 and S2, when S1 determines the value of S2.
```cpp
S1 -> R = 5;
S2 -> Area = 3.14 * R * R;

//S2 cannot be executed before S1 is executed
```

Within data dependence there are a few sub dependence types based on read write sequence:

| Type         | Mnemonic          | Example                     | Parallelizable? |
| ------------ | ----------------- | --------------------------- | --------------- |
| True (RAW)   | Read-After-Write  | `b = a + 1;` after `a = 5;` | ❌ No            |
| Anti (WAR)   | Write-After-Read  | `a = 4;` after `b = a + 1;` | ⚠️ Careful      |
| Output (WAW) | Write-After-Write | `a = 5;` → `a = 6;`         | ⚠️ Careful      |
| Input (RAR)  | Read-After-Read   | `a + b;`, `a + 1;`          | ✅ Yes           |

Anti and output can be removed by renaming.

- `a[i] = a[i-1] * 2` — **True dependence**: each iteration reads a value written by the previous iteration, forcing sequential execution.
    
- `a[i-2] = a[i] + 3` — **Anti-dependence**: a later iteration writes to a location read by an earlier iteration, restricting parallelization order.

Dependence Analysis mostly goes on in the actual source code and its main focus is on arrays.

#### Eliminating Anti Dependence

`a[i-1] = a[i] + 2` can not be parallelized because for e.g a[2] will be fetched to write in when i = 3 and to read from when i = 2 and the sequence. What we can do instead is, since we want a later value, we want the value before computation. So, for this we can have a copy of the array that we never edit to get the unedited value. This way we can run all the iterations in parallel e.g. `a[i-1] = b[i] + 2` where b is an original copy of a.

#### Loop carried dependence
If two statements access the same memory and at least one of them writes in it, they are dependent. When we are in a nested loop, if this dependence exists in one of them, we have to run it serially but we can parallelize the other loop.

```cpp
for (int i = 0; i < N; i++) {
    for (int j = 1; j < N; j++) {
        A[i][j] = A[i][j - 1] + 1;
    }
}

// Here every iteration at (i,j) reads from A[i][j-1] and writes to A[i][j]
// This means we can parallelize the outer loop but not the inner
```


#### Iteration Vectors
An execution of `S1` at `i = 2`, `j = 3` has an **iteration vector** of `(2,3)` — it tells you _where you are_ in the loop nest.

#### Iteration Space
All the possible iteration vectors of a loop nest.  For example: all values `(i,j)` for `0 <= i,j < N`

#### Distance Vector = Sink-Source
**Source:** The first iteration vector where a memory was accessed.
**Sink:** The second iteration vector where that same memory was accessed.

For example
```cpp
for (int i = 0; i < N; i++) {
    for (int j = 1; j < N; j++) {
        A[i][j] = A[i][j - 1] + 1;
    }
}
```

Here `A[i][j-1]` is first accessed at `A[i][j-1]` or in iteration vector terms ( i , j-1 ) -> Source, and accessed a second time at `A[i][j]` or ( i , j ) -> Sink. 

In this case Distance Vector is, ( i , j ) - ( i , j-1 ) -> (0,1).

#### Direction Vector
Describes the location of sink with respect to source. for example in the above case where the direction vector was (0,1), The direction vector would be (=,<). This means that `i` is in the same inner loop and `j` is in the next iteration of the inner loop. Since something like `j+1` would not cause **true dependence** issues, using `>` (sink before source) doesn’t matter for true dependences — but it **does matter** for anti-dependences.



